{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentEval usage example\n",
    "\n",
    "* Clone repo from FAIR github\n",
    "```\n",
    "    git clone https://github.com/facebookresearch/SentEval.git\n",
    "    cd SentEval/\n",
    "```\n",
    "* Dependencies:\n",
    "    * Python 2/3 with NumPy/SciPy\n",
    "    * Pytorch\n",
    "    * scikit-learn>=0.18.0\n",
    "\n",
    "* Install senteval\n",
    "```\n",
    "    python setup.py install\n",
    "```\n",
    "* Download datasets (it takes some time...)\n",
    "    * these are downstream tasks\n",
    "    * new Senteval also has probing tasks (https://github.com/facebookresearch/SentEval/tree/master/data/probing) for evaluating linguistic properties of your embeddings. \n",
    "```\n",
    "    cd data/downstream/\n",
    "    ./get_transfer_data.bash\n",
    "```\n",
    "* Download pretained Glove embeddings:\n",
    "\n",
    "```\n",
    "    mkdir pretrained\n",
    "    cd pretrained\n",
    "    wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "   \n",
    "```\n",
    "\n",
    "* The following code evaluates Glove pretrained embeddings on different NLP downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#Source for SIF functions: https://github.com/PrincetonML/SIF\n",
    "\n",
    "def load_pickled_data(filename):\n",
    "    \"\"\"\n",
    "    Load pickled adata\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "def save_word_probs():\n",
    "    #Get for each word a probability based on the training data (europarl)\n",
    "    with open('hansards/training.en') as f:\n",
    "        text = f.readlines()\n",
    "    sentences = [x.strip() for x in text]\n",
    "    splitted_sentences = [s.split() for s in sentences]\n",
    "    splitted_sentences = [[w.lower() for w in sentence] for sentence in splitted_sentences]\n",
    "    final = [item for sentence in splitted_sentences for item in sentence]\n",
    "    #Count all the occurences of each world and use this to determine the probabilities\n",
    "    counter = Counter(final)\n",
    "    total_count = sum(counter.values())\n",
    "    w_probs = {}\n",
    "    for word,count in counter.items():\n",
    "        w_probs[word] = count/total_count\n",
    "    #Write probabilities to file\n",
    "    with open('word_probabilities.pickle', 'wb') as handle:\n",
    "        pickle.dump(w_probs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def get_word_probs(batch):\n",
    "    splitted_sentences = [[w.lower() for w in sentence] for sentence in batch]\n",
    "    final = [item for sentence in splitted_sentences for item in sentence]\n",
    "    counter = Counter(final)\n",
    "    total_count = sum(counter.values())\n",
    "    w_probs = {}\n",
    "    for word,count in counter.items():\n",
    "        w_probs[word] = count/total_count\n",
    "    return w_probs\n",
    "\n",
    "\n",
    "\n",
    "model = Word2Vec.load('skipgram-100d-50e-mincount0.bin')\n",
    "index2word = model.wv.index2word\n",
    "embeddings = model.syn1neg\n",
    "word2index = dict(zip(index2word, range(len(index2word))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 14:47:48,296 : ***** Transfer task : MR *****\n",
      "\n",
      "\n",
      "2018-05-30 14:47:48,301 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:47:48,302 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:47:48,304 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n",
      "2018-05-30 14:47:48,483 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:47:48,484 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:47:48,485 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:47:48,486 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:47:48,562 : Generating sentence embeddings\n",
      "2018-05-30 14:47:48,596 : Generated sentence embeddings\n",
      "2018-05-30 14:47:48,602 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n",
      "2018-05-30 14:47:48,724 : Best param found at split 1: l2reg = 1                 with score 60.33\n",
      "2018-05-30 14:47:48,807 : Best param found at split 2: l2reg = 0.25                 with score 57.71\n",
      "2018-05-30 14:47:48,885 : Best param found at split 3: l2reg = 2                 with score 59.71\n",
      "2018-05-30 14:47:48,968 : Best param found at split 4: l2reg = 0.25                 with score 56.95\n",
      "2018-05-30 14:47:49,062 : Best param found at split 5: l2reg = 1                 with score 59.81\n",
      "2018-05-30 14:47:49,146 : Best param found at split 6: l2reg = 0.25                 with score 56.95\n",
      "2018-05-30 14:47:49,234 : Best param found at split 7: l2reg = 0.25                 with score 56.95\n",
      "2018-05-30 14:47:49,329 : Best param found at split 8: l2reg = 1                 with score 58.38\n",
      "2018-05-30 14:47:49,419 : Best param found at split 9: l2reg = 0.25                 with score 56.95\n",
      "2018-05-30 14:47:49,521 : Best param found at split 10: l2reg = 0.25                 with score 56.95\n",
      "2018-05-30 14:47:49,524 : Dev acc : 58.07 Test acc : 55.69\n",
      "\n",
      "2018-05-30 14:47:49,525 : ***** Transfer task : CR *****\n",
      "\n",
      "\n",
      "2018-05-30 14:47:49,538 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:47:49,538 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:47:49,540 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n",
      "2018-05-30 14:47:49,746 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:47:49,747 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:47:49,747 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:47:49,749 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:47:49,811 : Generating sentence embeddings\n",
      "2018-05-30 14:47:50,287 : Generated sentence embeddings\n",
      "2018-05-30 14:47:50,289 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n",
      "2018-05-30 14:47:52,911 : Best param found at split 1: l2reg = 8                 with score 71.62\n",
      "2018-05-30 14:47:55,806 : Best param found at split 2: l2reg = 8                 with score 71.3\n",
      "2018-05-30 14:47:58,382 : Best param found at split 3: l2reg = 2                 with score 71.71\n",
      "2018-05-30 14:48:01,020 : Best param found at split 4: l2reg = 4                 with score 71.71\n",
      "2018-05-30 14:48:03,577 : Best param found at split 5: l2reg = 4                 with score 71.45\n",
      "2018-05-30 14:48:06,123 : Best param found at split 6: l2reg = 8                 with score 71.8\n",
      "2018-05-30 14:48:08,792 : Best param found at split 7: l2reg = 8                 with score 71.33\n",
      "2018-05-30 14:48:11,484 : Best param found at split 8: l2reg = 1                 with score 71.42\n",
      "2018-05-30 14:48:14,099 : Best param found at split 9: l2reg = 2                 with score 71.61\n",
      "2018-05-30 14:48:16,647 : Best param found at split 10: l2reg = 8                 with score 71.7\n",
      "2018-05-30 14:48:16,709 : Dev acc : 71.57 Test acc : 72.03\n",
      "\n",
      "2018-05-30 14:48:16,712 : ***** Transfer task : MPQA *****\n",
      "\n",
      "\n",
      "2018-05-30 14:48:16,729 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:48:16,730 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:48:16,731 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n",
      "2018-05-30 14:48:16,846 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:48:16,847 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:48:16,848 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:48:16,849 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:48:16,949 : Generating sentence embeddings\n",
      "2018-05-30 14:48:17,305 : Generated sentence embeddings\n",
      "2018-05-30 14:48:17,307 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n",
      "2018-05-30 14:48:26,434 : Best param found at split 1: l2reg = 0.25                 with score 83.09\n",
      "2018-05-30 14:48:35,596 : Best param found at split 2: l2reg = 0.25                 with score 83.29\n",
      "2018-05-30 14:48:44,754 : Best param found at split 3: l2reg = 2                 with score 83.24\n",
      "2018-05-30 14:48:53,895 : Best param found at split 4: l2reg = 4                 with score 83.55\n",
      "2018-05-30 14:49:02,572 : Best param found at split 5: l2reg = 0.5                 with score 82.89\n",
      "2018-05-30 14:49:11,799 : Best param found at split 6: l2reg = 1                 with score 83.26\n",
      "2018-05-30 14:49:20,919 : Best param found at split 7: l2reg = 8                 with score 83.23\n",
      "2018-05-30 14:49:30,117 : Best param found at split 8: l2reg = 0.5                 with score 83.42\n",
      "2018-05-30 14:49:39,205 : Best param found at split 9: l2reg = 4                 with score 83.31\n",
      "2018-05-30 14:49:48,269 : Best param found at split 10: l2reg = 8                 with score 83.16\n",
      "2018-05-30 14:49:48,421 : Dev acc : 83.24 Test acc : 83.08\n",
      "\n",
      "2018-05-30 14:49:48,424 : ***** Transfer task : SUBJ *****\n",
      "\n",
      "\n",
      "2018-05-30 14:49:48,459 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:49:48,460 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:49:48,461 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n",
      "2018-05-30 14:49:48,582 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:49:48,582 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:49:48,583 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:49:48,584 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:49:48,640 : Generating sentence embeddings\n",
      "2018-05-30 14:49:49,997 : Generated sentence embeddings\n",
      "2018-05-30 14:49:49,999 : Training sklearn-LogReg with (inner) 10-fold cross-validation\n",
      "2018-05-30 14:49:57,576 : Best param found at split 1: l2reg = 2                 with score 83.13\n",
      "2018-05-30 14:50:05,225 : Best param found at split 2: l2reg = 1                 with score 83.16\n",
      "2018-05-30 14:50:13,653 : Best param found at split 3: l2reg = 1                 with score 83.28\n",
      "2018-05-30 14:50:21,391 : Best param found at split 4: l2reg = 2                 with score 83.29\n",
      "2018-05-30 14:50:29,521 : Best param found at split 5: l2reg = 2                 with score 83.23\n",
      "2018-05-30 14:50:37,156 : Best param found at split 6: l2reg = 2                 with score 83.28\n",
      "2018-05-30 14:50:44,986 : Best param found at split 7: l2reg = 1                 with score 83.29\n",
      "2018-05-30 14:50:52,536 : Best param found at split 8: l2reg = 4                 with score 83.41\n",
      "2018-05-30 14:51:00,672 : Best param found at split 9: l2reg = 8                 with score 83.22\n",
      "2018-05-30 14:51:08,122 : Best param found at split 10: l2reg = 8                 with score 83.27\n",
      "2018-05-30 14:51:08,287 : Dev acc : 83.26 Test acc : 83.22\n",
      "\n",
      "2018-05-30 14:51:08,290 : ***** Transfer task : SST Binary classification *****\n",
      "\n",
      "\n",
      "2018-05-30 14:51:08,565 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:51:08,566 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:51:08,568 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 14:51:08,690 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:51:08,691 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:51:08,691 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:51:08,692 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:51:08,733 : Computing embedding for train\n",
      "2018-05-30 14:51:12,936 : Computed train embeddings\n",
      "2018-05-30 14:51:12,937 : Computing embedding for dev\n",
      "2018-05-30 14:51:13,055 : Computed dev embeddings\n",
      "2018-05-30 14:51:13,056 : Computing embedding for test\n",
      "2018-05-30 14:51:13,484 : Computed test embeddings\n",
      "2018-05-30 14:51:13,485 : Training sklearn-LogReg with standard validation..\n",
      "2018-05-30 14:51:20,766 : [('reg:0.25', 68.23), ('reg:0.5', 68.23), ('reg:1', 68.35), ('reg:2', 68.35), ('reg:4', 68.35), ('reg:8', 68.35)]\n",
      "2018-05-30 14:51:20,767 : Validation : best param found is reg = 1 with score             68.35\n",
      "2018-05-30 14:51:20,768 : Evaluating...\n",
      "2018-05-30 14:51:22,033 : \n",
      "Dev acc : 68.35 Test acc : 67.27 for             SST Binary classification\n",
      "\n",
      "2018-05-30 14:51:22,040 : ***** Transfer task : TREC *****\n",
      "\n",
      "\n",
      "2018-05-30 14:51:22,102 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:51:22,103 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:51:22,104 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n",
      "2018-05-30 14:51:22,274 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:51:22,274 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:51:22,275 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:51:22,276 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:51:22,639 : Computed train embeddings\n",
      "2018-05-30 14:51:22,676 : Computed test embeddings\n",
      "2018-05-30 14:51:22,678 : Training sklearn-LogReg with 10-fold cross-validation\n",
      "2018-05-30 14:52:01,795 : [('reg:0.5', 57.06), ('reg:1', 57.63), ('reg:2', 58.38), ('reg:4', 58.49), ('reg:8', 58.38), ('reg:16', 58.35), ('reg:32', 58.31)]\n",
      "2018-05-30 14:52:01,796 : Cross-validation : best param found is reg = 4             with score 58.49\n",
      "2018-05-30 14:52:01,797 : Evaluating...\n",
      "2018-05-30 14:52:02,386 : \n",
      "Dev acc : 58.49 Test acc : 61.6             for TREC\n",
      "\n",
      "2018-05-30 14:52:02,389 : ***** Transfer task : MRPC *****\n",
      "\n",
      "\n",
      "2018-05-30 14:52:02,434 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:52:02,435 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:52:02,436 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n",
      "2018-05-30 14:52:02,597 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:52:02,598 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:52:02,599 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:52:02,600 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:52:02,639 : Computing embedding for train\n",
      "2018-05-30 14:52:03,538 : Computed train embeddings\n",
      "2018-05-30 14:52:03,539 : Computing embedding for test\n",
      "2018-05-30 14:52:03,964 : Computed test embeddings\n",
      "2018-05-30 14:52:03,978 : Training sklearn-LogReg with 10-fold cross-validation\n",
      "2018-05-30 14:52:11,433 : [('reg:0.5', 69.63), ('reg:1', 70.0), ('reg:2', 70.39), ('reg:4', 70.14), ('reg:8', 70.24), ('reg:16', 70.05), ('reg:32', 70.27)]\n",
      "2018-05-30 14:52:11,434 : Cross-validation : best param found is reg = 2             with score 70.39\n",
      "2018-05-30 14:52:11,435 : Evaluating...\n",
      "2018-05-30 14:52:11,547 : Dev acc : 70.39 Test acc 70.67; Test F1 80.46 for MRPC.\n",
      "\n",
      "2018-05-30 14:52:11,551 : ***** Transfer task : SICK-Entailment*****\n",
      "\n",
      "\n",
      "2018-05-30 14:52:11,601 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:52:11,602 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:52:11,603 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n",
      "2018-05-30 14:52:11,719 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:52:11,720 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:52:11,720 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:52:11,721 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:52:11,762 : Computing embedding for train\n",
      "2018-05-30 14:52:12,316 : Computed train embeddings\n",
      "2018-05-30 14:52:12,317 : Computing embedding for dev\n",
      "2018-05-30 14:52:12,386 : Computed dev embeddings\n",
      "2018-05-30 14:52:12,386 : Computing embedding for test\n",
      "2018-05-30 14:52:13,017 : Computed test embeddings\n",
      "2018-05-30 14:52:13,039 : Training sklearn-LogReg with standard validation..\n",
      "2018-05-30 14:52:15,309 : [('reg:0.25', 67.8), ('reg:0.5', 69.2), ('reg:1', 71.4), ('reg:2', 72.2), ('reg:4', 71.6), ('reg:8', 71.4)]\n",
      "2018-05-30 14:52:15,310 : Validation : best param found is reg = 2 with score             72.2\n",
      "2018-05-30 14:52:15,310 : Evaluating...\n",
      "2018-05-30 14:52:15,712 : \n",
      "Dev acc : 72.2 Test acc : 71.38 for                        SICK entailment\n",
      "\n",
      "2018-05-30 14:52:15,719 : ***** Transfer task : STS14 *****\n",
      "\n",
      "\n",
      "2018-05-30 14:52:15,777 : loading Word2Vec object from skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:52:15,778 : {'kw': {}, 'mode': 'rb', 'uri': 'skipgram-100d-50e-mincount0.bin'}\n",
      "2018-05-30 14:52:15,779 : encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='skipgram-100d-50e-mincount0.bin'>}\n",
      "2018-05-30 14:52:15,902 : loading wv recursively from skipgram-100d-50e-mincount0.bin.wv.* with mmap=None\n",
      "2018-05-30 14:52:15,903 : setting ignored attribute syn0norm to None\n",
      "2018-05-30 14:52:15,904 : setting ignored attribute cum_table to None\n",
      "2018-05-30 14:52:15,905 : loaded skipgram-100d-50e-mincount0.bin\n",
      "2018-05-30 14:52:16,069 : deft-forum : pearson = 0.3028, spearman = 0.3573\n",
      "2018-05-30 14:52:16,164 : deft-news : pearson = 0.6081, spearman = 0.5920\n",
      "2018-05-30 14:52:16,311 : headlines : pearson = 0.4518, spearman = 0.4923\n",
      "2018-05-30 14:52:16,491 : images : pearson = 0.6210, spearman = 0.6354\n",
      "2018-05-30 14:52:16,655 : OnWN : pearson = 0.6969, spearman = 0.7324\n",
      "2018-05-30 14:52:16,831 : tweet-news : pearson = 0.5685, spearman = 0.5707\n",
      "2018-05-30 14:52:16,832 : ALL (weighted average) : Pearson = 0.5526,             Spearman = 0.5764\n",
      "2018-05-30 14:52:16,833 : ALL (average) : Pearson = 0.5415,             Spearman = 0.5633\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MR': {'devacc': 58.07, 'acc': 55.69, 'ndev': 74, 'ntest': 74}, 'CR': {'devacc': 71.57, 'acc': 72.03, 'ndev': 3775, 'ntest': 3775}, 'MPQA': {'devacc': 83.24, 'acc': 83.08, 'ndev': 10606, 'ntest': 10606}, 'SUBJ': {'devacc': 83.26, 'acc': 83.22, 'ndev': 10000, 'ntest': 10000}, 'SST2': {'devacc': 68.35, 'acc': 67.27, 'ndev': 872, 'ntest': 1821}, 'TREC': {'devacc': 58.49, 'acc': 61.6, 'ndev': 5452, 'ntest': 500}, 'MRPC': {'devacc': 70.39, 'acc': 70.67, 'f1': 80.46, 'ndev': 4076, 'ntest': 1725}, 'SICKEntailment': {'devacc': 72.2, 'acc': 71.38, 'ndev': 500, 'ntest': 4927}, 'STS14': {'deft-forum': {'pearson': (0.30277773334673425, 5.394608121020304e-11), 'spearman': SpearmanrResult(correlation=0.35728776598497364, pvalue=5.381483819848277e-15), 'nsamples': 450}, 'deft-news': {'pearson': (0.6080544324892407, 1.0175134163520799e-31), 'spearman': SpearmanrResult(correlation=0.5919665363954733, pvalue=9.361698052393679e-30), 'nsamples': 300}, 'headlines': {'pearson': (0.4517861088805761, 5.3282103300430434e-39), 'spearman': SpearmanrResult(correlation=0.4922744531487671, pvalue=4.960348144641728e-47), 'nsamples': 750}, 'images': {'pearson': (0.6209553515670647, 3.5928384270478977e-81), 'spearman': SpearmanrResult(correlation=0.63543463425529, pvalue=4.610395009935302e-86), 'nsamples': 750}, 'OnWN': {'pearson': (0.696947683178574, 4.0236491625493266e-110), 'spearman': SpearmanrResult(correlation=0.7323689110304953, pvalue=5.6207154274874335e-127), 'nsamples': 750}, 'tweet-news': {'pearson': (0.5684588867892761, 2.061526737380107e-65), 'spearman': SpearmanrResult(correlation=0.5706505561883717, pvalue=5.156099452399928e-66), 'nsamples': 750}, 'all': {'pearson': {'mean': 0.5414966993752444, 'wmean': 0.5526072886838456}, 'spearman': {'mean': 0.5633304761672284, 'wmean': 0.5763775657544196}}}}\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "#\n",
    "\n",
    "from __future__ import absolute_import, division, unicode_literals\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import sklearn\n",
    "import SentEval.examples.data as data\n",
    "# Set PATHs\n",
    "# path to senteval\n",
    "PATH_TO_SENTEVAL = 'SentEval/'\n",
    "# path to the NLP datasets \n",
    "PATH_TO_DATA = 'SentEval/data'\n",
    "# path to glove embeddings\n",
    "PATH_TO_VEC = 'SentEval/data/downstream/pretrained/glove.840B.300d.txt'\n",
    "\n",
    "\n",
    "# import SentEval\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval\n",
    "\n",
    "\n",
    "def prepare(params, samples):\n",
    "    \"\"\"\n",
    "    In this example we are going to load Glove, \n",
    "    here you will initialize your model.\n",
    "    remember to add what you model needs into the params dictionary\n",
    "\n",
    "    _, params.word2id = data.create_dictionary(samples)\n",
    "    # load glove/word2vec format \n",
    "    params.word_vec = data.get_wordvec(PATH_TO_VEC, params.word2id)\n",
    "    # dimensionality of glove embeddings\n",
    "    params.wvec_dim = 300\n",
    "    \"\"\"\n",
    "\n",
    "    model = Word2Vec.load('skipgram-100d-50e-mincount0.bin')\n",
    "    index2word = model.wv.index2word\n",
    "    embeddings = model.syn1neg\n",
    "    word2index = dict(zip(index2word, range(len(index2word))))\n",
    "    \n",
    "    params.word2id = word2index\n",
    "    params.wvec_dim = 100\n",
    "    params.word_vec = model.syn1neg\n",
    "    params.batch_size = 128\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "def average_batch(params, batch):\n",
    "    \"\"\"\n",
    "    In this example we use the average of word embeddings as a sentence representation.\n",
    "    Each batch consists of one vector for sentence.\n",
    "    Here you can process each sentence of the batch, \n",
    "    or a complete batch (you may need masking for that).\n",
    "    \n",
    "    \"\"\"\n",
    "    # if a sentence is empty dot is set to be the only token\n",
    "    # you can change it into NULL dependening in your model\n",
    "    batch = [sent if sent != [] else ['.'] for sent in batch]\n",
    "    embeddings = []\n",
    "    for sent in batch:\n",
    "        sentvec = []\n",
    "        # the format of a sentence is a lists of words (tokenized and lowercased)\n",
    "        for word in sent:\n",
    "            if word in params.word2id.keys():\n",
    "                # [number of words, embedding dimensionality]\n",
    "                sentvec.append(params.word_vec[params.word2id[word]])\n",
    "        if not sentvec:\n",
    "            vec = np.ones(params.wvec_dim)\n",
    "            # [number of words, embedding dimensionality]\n",
    "            sentvec.append(vec)\n",
    "        # average of word embeddings for sentence representation\n",
    "        # [embedding dimansionality]\n",
    "        sentvec = np.mean(sentvec, 0)\n",
    "        embeddings.append(sentvec)\n",
    "    # [batch size, embedding dimensionality]\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings \n",
    "\n",
    "def weighted_average_full_batch(params, batch):\n",
    "    #Get the weighted average of each word embedding to construct a sentence embedding\n",
    "    #The embeddings for each word get scaled with a factor 0.001/(0.001+p(w)) where\n",
    "    #p(w) is computed based on the hansards (Europarl) word frequencies\n",
    "    \n",
    "    batch = [sent if sent != [] else ['.'] for sent in batch]\n",
    "    embeddings = []\n",
    "    a = 0.01\n",
    "    average_prob = 1/(len(word2index))\n",
    "    \n",
    "    for sent in batch:\n",
    "        sentence_length = len(sent)\n",
    "        sentvec = np.zeros(params.wvec_dim,)\n",
    "        for word in sent:\n",
    "            if word in params.word2id.keys():\n",
    "                p_w = probs.get(word,average_prob)\n",
    "                scale = a/(a+p_w)\n",
    "                emb = params.word_vec[params.word2id[word]]*scale\n",
    "                sentvec = np.add(sentvec,emb)\n",
    "        if np.sum(sentvec) == 0.0:\n",
    "            sentvec = np.ones(params.wvec_dim)\n",
    "        embeddings.append(sentvec/sentence_length)\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "def weighted_average_batch2(params, batch):\n",
    "    #Get the weighted average of each word embedding to construct a sentence embedding\n",
    "    #The embeddings for each word get scaled with a factor 0.001/(0.001+p(w)) where\n",
    "    #p(w) is computed based on the word frequencies in the batch\n",
    "    \n",
    "    batch = [sent if sent != [] else ['.'] for sent in batch]\n",
    "    embeddings = []\n",
    "    a = 0.001\n",
    "    word_prob_batch = get_word_probs(batch)\n",
    "\n",
    "    for sent in batch:\n",
    "        sentence_length = len(sent)\n",
    "        sentvec = np.zeros(params.wvec_dim,)\n",
    "        for word in sent:\n",
    "            if word in params.word2id.keys():\n",
    "                p_w = word_prob_batch[word]\n",
    "                scale = a/(a+p_w)\n",
    "                emb = params.word_vec[params.word2id[word]]*scale\n",
    "                sentvec = np.add(sentvec,emb)\n",
    "        if np.sum(sentvec) == 0.0:\n",
    "            sentvec = np.ones(params.wvec_dim)\n",
    "        embeddings.append(sentvec/sentence_length)\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "probs = load_pickled_data('word_probabilities.pickle')\n",
    "\n",
    "# Set params for SentEval\n",
    "# we use logistic regression (usepytorch: Fasle) and kfold 10\n",
    "# In this dictionary you can add extra information that you model needs for initialization\n",
    "# for example the path to a dictionary of indices, of hyper parameters\n",
    "# this dictionary is passed to the batched and the prepare fucntions\n",
    "params_senteval = {'task_path': PATH_TO_DATA, 'usepytorch': False, 'kfold': 10}\n",
    "# this is the config for the NN classifier but we are going to use scikit-learn logistic regression with 10 kfold\n",
    "#usepytorch = False \n",
    "#params_senteval['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 256,\n",
    "                                # 'tenacity': 3, 'epoch_size': 2}\n",
    "# Set up logger\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    se = senteval.engine.SE(params_senteval, weighted_average_full_batch, prepare)\n",
    "    \n",
    "    # here you define the NLP taks that your embedding model is going to be evaluated\n",
    "    # in (https://arxiv.org/abs/1802.05883) we use the following :\n",
    "    # SICKRelatedness (Sick-R) needs torch cuda to work (even when using logistic regression), \n",
    "    # but STS14 (semantic textual similarity) is a similar type of semantic task\n",
    "    transfer_tasks = ['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC',\n",
    "                      'MRPC', 'SICKEntailment', 'STS14']\n",
    "    # senteval prints the results and returns a dictionary with the scores\n",
    "    results = se.eval(transfer_tasks)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('results/skipgram_results_batcher_wa001.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR 55.69\n",
      "CR 72.03\n",
      "MPQA 83.08\n",
      "SUBJ 83.22\n",
      "SST2 67.27\n",
      "TREC 61.6\n",
      "MRPC 70.67\n",
      "SICKEntailment 71.38\n",
      "STS14 no acc\n"
     ]
    }
   ],
   "source": [
    "for k,v in results.items():\n",
    "    try:\n",
    "        print(k, v['acc'])\n",
    "    except:\n",
    "        print(k, \"no acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearson': {'mean': 0.5414966993752444, 'wmean': 0.5526072886838456}, 'spearman': {'mean': 0.5633304761672284, 'wmean': 0.5763775657544196}}\n"
     ]
    }
   ],
   "source": [
    "print(results['STS14']['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
